{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22262cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.getcwd()\n",
    "os.chdir('C://kiosks_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4237d4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "from openai import OpenAI\n",
    "import json\n",
    "\n",
    "\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "client = OpenAI(api_key=openai_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "24e79485",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('main\\\\components\\\\menu_maneger\\\\pdf_dir\\\\reviewed_menu_data.json', 'r') as menu_json_file:\n",
    "    data = json.load(menu_json_file)\n",
    "    data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "118853c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'item_name': 'Dhaniya Paneer Tikka',\n",
       "  'price': '675',\n",
       "  'description': 'Apricot, almond slivers, corn chat, pickled mango dip'},\n",
       " {'item_name': 'Chicken or Paneer Kathi Roll',\n",
       "  'price': '750',\n",
       "  'description': 'Grilled chicken tikka or paneer tikka, green apple relish, mint chutney'},\n",
       " {'item_name': 'Pav Bhaji',\n",
       "  'price': '685',\n",
       "  'description': 'Classic Bombay street food, spicy mashed potatoes & vegetable mixture,'},\n",
       " {'item_name': 'Kheema Ghotala',\n",
       "  'price': '785',\n",
       "  'description': 'Bombay street food classic, spiced minced lamb, egg,'},\n",
       " {'item_name': 'Goan Pomfret Curry',\n",
       "  'price': '1325',\n",
       "  'description': 'Mildly spiced coconut curry flavoured with Garcinia indica rind,'},\n",
       " {'item_name': 'Vegetable Club Sandwich',\n",
       "  'price': '685',\n",
       "  'description': 'Russian salad, tomato, cheese, iceberg lettuce'},\n",
       " {'item_name': 'Vegetarian Panini sandwich',\n",
       "  'price': '685',\n",
       "  'description': 'Herbed mushroom, grilled pimentos, avocado, provolone cheese,'},\n",
       " {'item_name': 'Classic Club Sandwich',\n",
       "  'price': '685',\n",
       "  'description': 'Chicken slices, fried egg, ham, cheese, tomato, iceberg lettuce'}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3c2161d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_input = 'get me couple of Classic Club Sandwich along with two Kheema Ghotala'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "598bfcce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-BM9rYrRmP1hyZCLGTGzb9PaoZajbH', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='```json\\n[\\n    {\\n        \"item_name\": \"Classic Club Sandwich\",\\n        \"quantity\": 2\\n    },\\n    {\\n        \"item_name\": \"Kheema Ghotala\",\\n        \"quantity\": 2\\n    }\\n]\\n```', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1744620828, model='gpt-4-1106-preview', object='chat.completion', service_tier='default', system_fingerprint=None, usage=CompletionUsage(completion_tokens=52, prompt_tokens=351, total_tokens=403, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4-1106-preview\",\n",
    "    # messages=[\n",
    "    #     {\"role\": \"system\", \"content\": \"You're a restaurant order extractor. Match spoken order to menu items.\"},\n",
    "    #     {\"role\": \"user\", \"content\": f\"Menu items: {data}\\nCustomer said: {sample_input}\\n\\nReturn a JSON list with item_name and quantity.\"}\n",
    "    # ],\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You're a restaurant order extractor. Match spoken order to menu items and return a JSON list of item_name and quantity.\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"Menu items: {data}\\nCustomer said: {sample_input}\"\n",
    "        }\n",
    "    ],\n",
    "    temperature=0.2,\n",
    "    # # functions=[\n",
    "    #     {\n",
    "    #         \"name\": \"extract_order\",\n",
    "    #         \"parameters\": {\n",
    "    #             \"type\": \"object\",\n",
    "    #             \"properties\": {\n",
    "    #                 \"order\": {\n",
    "    #                     \"type\": \"array\",\n",
    "    #                     \"items\": {\n",
    "    #                         \"type\": \"object\",\n",
    "    #                         \"properties\": {\n",
    "    #                             \"item_name\": {\"type\": \"string\"},\n",
    "    #                             \"quantity\": {\"type\": \"integer\"}\n",
    "    #                         },\n",
    "    #                         \"required\": [\"item_name\", \"quantity\"]\n",
    "    #                     }\n",
    "    #                 }\n",
    "    #             },\n",
    "    #             \"required\": [\"order\"]\n",
    "    #         }\n",
    "    #     }\n",
    "    # ],\n",
    "    # function_call={\"name\": \"extract_order\"}\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f5162266",
   "metadata": {},
   "outputs": [],
   "source": [
    "function_call = response.choices[0].message.content\n",
    "# function_call = response.choices[0].message.function_call\n",
    "# order_data = json.loads(function_call)\n",
    "# order_data\n",
    "# Remove markdown code block syntax\n",
    "json_str = function_call.split('```json\\n')[1].split('\\n```')[0]\n",
    "order_items = json.loads(json_str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6706a22c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'item_name': 'Classic Club Sandwich', 'quantity': 2},\n",
       " {'item_name': 'Kheema Ghotala', 'quantity': 2}]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "order_items"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe950ac",
   "metadata": {},
   "source": [
    "## Trying from free api model GROQ or Langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9a7de0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from groq import Groq\n",
    "\n",
    "client = Groq(api_key=os.getenv('GROQ_API_KEY'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "071b2efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "completion = client.chat.completions.create(\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You're a restaurant order extractor. Match spoken order to menu items with price and return a just JSON list of item_name, price and price quantity. Nothing other than that\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"Menu items: {data}\\nCustomer said: {sample_input}\"\n",
    "        }\n",
    "    ],\n",
    "    temperature=1,\n",
    "    max_completion_tokens=1024,\n",
    "    # top_p=1,\n",
    "    # stream=True,\n",
    "    # stop=None,\n",
    ")\n",
    "\n",
    "# for chunk in completion:\n",
    "#     print(chunk.choices[0].delta.content or \"\", end=\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "61e47be8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'item_name': 'Classic Club Sandwich', 'price': 685, 'quantity': 2}, {'item_name': 'Kheema Ghotala', 'price': 785, 'quantity': 2}]\n"
     ]
    }
   ],
   "source": [
    "output_json = completion.choices[0].message.content\n",
    "order_items = json.loads(output_json)\n",
    "print(order_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f6fb1d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "empty\n"
     ]
    }
   ],
   "source": [
    "path = 'models\\\\m'\n",
    "import os\n",
    "if not os.listdir(path):\n",
    "    print('empty') \n",
    "else:\n",
    "    print('d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12208e99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cefc45f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_model(self):\n",
    "        '''\n",
    "        \n",
    "        \n",
    "        '''\n",
    "        tokenizer = AutoTokenizer.from_pretrained(self.config['base_model_id'], token=token)\n",
    "        \n",
    "        model = AutoModelForCausalLM.from_pretrained(\n",
    "            self.config['base_model_id'],\n",
    "            device_map=\"auto\",            # Automatically uses GPU if available\n",
    "            torch_dtype=\"auto\",           # Adjusts precision\n",
    "            trust_remote_code=True,\n",
    "            token= token\n",
    "        )\n",
    "\n",
    "        # Optional: wrap in a pipeline\n",
    "        llm = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\n",
    "        \n",
    "        # Prompt (e.g., for restaurant order understanding)\n",
    "                \n",
    "        prompt =[{\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": \"You're a restaurant order extractor. Match spoken order to menu items with price and return a just JSON list of item_name, price and price quantity. Nothing other than that\"\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": f\"Menu items: {data}\\nCustomer said: {sample_input}\"\n",
    "                }]\n",
    "        prompt = json.dumps(prompt)\n",
    "                \n",
    "        response = llm(prompt, max_new_tokens=256, do_sample=False)[0][\"generated_text\"]\n",
    "        print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fed5f92",
   "metadata": {},
   "source": [
    "### Trying with fine tunned model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f0e90315",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_input= 'hello may i see the menu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba0b317",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:3: SyntaxWarning: invalid escape sequence '\\Q'\n",
      "<>:4: SyntaxWarning: invalid escape sequence '\\Q'\n",
      "<>:6: SyntaxWarning: invalid escape sequence '\\c'\n",
      "<>:3: SyntaxWarning: invalid escape sequence '\\Q'\n",
      "<>:4: SyntaxWarning: invalid escape sequence '\\Q'\n",
      "<>:6: SyntaxWarning: invalid escape sequence '\\c'\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_16068\\519800662.py:3: SyntaxWarning: invalid escape sequence '\\Q'\n",
      "  model = AutoModelForCausalLM.from_pretrained('models\\Qwen2.5-0.5B-finetunned-Instruct-merged')\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_16068\\519800662.py:4: SyntaxWarning: invalid escape sequence '\\Q'\n",
      "  tokenizer = AutoTokenizer.from_pretrained('models\\Qwen2.5-0.5B-finetunned-Instruct-merged')\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_16068\\519800662.py:6: SyntaxWarning: invalid escape sequence '\\c'\n",
      "  with open('main\\components\\menu_maneger\\extracted_menu_dir\\manual_reviewed_menu_data.json') as data:\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "model = AutoModelForCausalLM.from_pretrained('models\\Qwen2.5-0.5B-finetunned-Instruct-merged')\n",
    "tokenizer = AutoTokenizer.from_pretrained('models\\Qwen2.5-0.5B-finetunned-Instruct-merged')\n",
    "\n",
    "with open('main\\components\\menu_maneger\\extracted_menu_dir\\manual_reviewed_menu_data.json') as data:\n",
    "    data = json.load(data)\n",
    "\n",
    "prompt = [{\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": \"You're a restaurant cashier you have manege the order and well interact with customer\"\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": f\"Menu items: {data}\\nCustomer said: {sample_input}\"\n",
    "                }]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c20e8a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "text input must be of type `str` (single example), `List[str]` (batch or single pretokenized example) or `List[List[str]]` (batch of pretokenized examples).",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28minput\u001b[39m = \u001b[43mtokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mpt\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m output = model.generate(**\u001b[38;5;28minput\u001b[39m, max_new_tokens=\u001b[32m100\u001b[39m)\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(tokenizer.decode(outputs[\u001b[32m0\u001b[39m], skip_special_tokens=\u001b[38;5;28;01mTrue\u001b[39;00m))\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\kiosks_\\myenv\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:2887\u001b[39m, in \u001b[36mPreTrainedTokenizerBase.__call__\u001b[39m\u001b[34m(self, text, text_pair, text_target, text_pair_target, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[39m\n\u001b[32m   2885\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._in_target_context_manager:\n\u001b[32m   2886\u001b[39m         \u001b[38;5;28mself\u001b[39m._switch_to_input_mode()\n\u001b[32m-> \u001b[39m\u001b[32m2887\u001b[39m     encodings = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_one\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_pair\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtext_pair\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mall_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2888\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m text_target \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   2889\u001b[39m     \u001b[38;5;28mself\u001b[39m._switch_to_target_mode()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\kiosks_\\myenv\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:2947\u001b[39m, in \u001b[36mPreTrainedTokenizerBase._call_one\u001b[39m\u001b[34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, split_special_tokens, **kwargs)\u001b[39m\n\u001b[32m   2944\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m   2946\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_valid_text_input(text):\n\u001b[32m-> \u001b[39m\u001b[32m2947\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   2948\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mtext input must be of type `str` (single example), `List[str]` (batch or single pretokenized example) \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2949\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mor `List[List[str]]` (batch of pretokenized examples).\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2950\u001b[39m     )\n\u001b[32m   2952\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m text_pair \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_valid_text_input(text_pair):\n\u001b[32m   2953\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   2954\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mtext input must be of type `str` (single example), `List[str]` (batch or single pretokenized example) \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2955\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mor `List[List[str]]` (batch of pretokenized examples).\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2956\u001b[39m     )\n",
      "\u001b[31mValueError\u001b[39m: text input must be of type `str` (single example), `List[str]` (batch or single pretokenized example) or `List[List[str]]` (batch of pretokenized examples)."
     ]
    }
   ],
   "source": [
    "input = tokenizer(prompt, return_tensors='pt')\n",
    "output = model.generate(**input, max_new_tokens=100)\n",
    "print(tokenizer.decode(output[0], skip_special_tokens=True))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
