{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22262cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.getcwd()\n",
    "os.chdir('C://kiosks_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4237d4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "from openai import OpenAI\n",
    "import json\n",
    "\n",
    "\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "client = OpenAI(api_key=openai_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "24e79485",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('main\\\\components\\\\menu_maneger\\\\pdf_dir\\\\reviewed_menu_data.json', 'r') as menu_json_file:\n",
    "    data = json.load(menu_json_file)\n",
    "    data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "118853c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'item_name': 'Dhaniya Paneer Tikka',\n",
       "  'price': '675',\n",
       "  'description': 'Apricot, almond slivers, corn chat, pickled mango dip'},\n",
       " {'item_name': 'Chicken or Paneer Kathi Roll',\n",
       "  'price': '750',\n",
       "  'description': 'Grilled chicken tikka or paneer tikka, green apple relish, mint chutney'},\n",
       " {'item_name': 'Pav Bhaji',\n",
       "  'price': '685',\n",
       "  'description': 'Classic Bombay street food, spicy mashed potatoes & vegetable mixture,'},\n",
       " {'item_name': 'Kheema Ghotala',\n",
       "  'price': '785',\n",
       "  'description': 'Bombay street food classic, spiced minced lamb, egg,'},\n",
       " {'item_name': 'Goan Pomfret Curry',\n",
       "  'price': '1325',\n",
       "  'description': 'Mildly spiced coconut curry flavoured with Garcinia indica rind,'},\n",
       " {'item_name': 'Vegetable Club Sandwich',\n",
       "  'price': '685',\n",
       "  'description': 'Russian salad, tomato, cheese, iceberg lettuce'},\n",
       " {'item_name': 'Vegetarian Panini sandwich',\n",
       "  'price': '685',\n",
       "  'description': 'Herbed mushroom, grilled pimentos, avocado, provolone cheese,'},\n",
       " {'item_name': 'Classic Club Sandwich',\n",
       "  'price': '685',\n",
       "  'description': 'Chicken slices, fried egg, ham, cheese, tomato, iceberg lettuce'}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3c2161d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_input = 'get me couple of Classic Club Sandwich along with two Kheema Ghotala'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "598bfcce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-BM9rYrRmP1hyZCLGTGzb9PaoZajbH', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='```json\\n[\\n    {\\n        \"item_name\": \"Classic Club Sandwich\",\\n        \"quantity\": 2\\n    },\\n    {\\n        \"item_name\": \"Kheema Ghotala\",\\n        \"quantity\": 2\\n    }\\n]\\n```', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1744620828, model='gpt-4-1106-preview', object='chat.completion', service_tier='default', system_fingerprint=None, usage=CompletionUsage(completion_tokens=52, prompt_tokens=351, total_tokens=403, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4-1106-preview\",\n",
    "    # messages=[\n",
    "    #     {\"role\": \"system\", \"content\": \"You're a restaurant order extractor. Match spoken order to menu items.\"},\n",
    "    #     {\"role\": \"user\", \"content\": f\"Menu items: {data}\\nCustomer said: {sample_input}\\n\\nReturn a JSON list with item_name and quantity.\"}\n",
    "    # ],\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You're a restaurant order extractor. Match spoken order to menu items and return a JSON list of item_name and quantity.\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"Menu items: {data}\\nCustomer said: {sample_input}\"\n",
    "        }\n",
    "    ],\n",
    "    temperature=0.2,\n",
    "    # # functions=[\n",
    "    #     {\n",
    "    #         \"name\": \"extract_order\",\n",
    "    #         \"parameters\": {\n",
    "    #             \"type\": \"object\",\n",
    "    #             \"properties\": {\n",
    "    #                 \"order\": {\n",
    "    #                     \"type\": \"array\",\n",
    "    #                     \"items\": {\n",
    "    #                         \"type\": \"object\",\n",
    "    #                         \"properties\": {\n",
    "    #                             \"item_name\": {\"type\": \"string\"},\n",
    "    #                             \"quantity\": {\"type\": \"integer\"}\n",
    "    #                         },\n",
    "    #                         \"required\": [\"item_name\", \"quantity\"]\n",
    "    #                     }\n",
    "    #                 }\n",
    "    #             },\n",
    "    #             \"required\": [\"order\"]\n",
    "    #         }\n",
    "    #     }\n",
    "    # ],\n",
    "    # function_call={\"name\": \"extract_order\"}\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f5162266",
   "metadata": {},
   "outputs": [],
   "source": [
    "function_call = response.choices[0].message.content\n",
    "# function_call = response.choices[0].message.function_call\n",
    "# order_data = json.loads(function_call)\n",
    "# order_data\n",
    "# Remove markdown code block syntax\n",
    "json_str = function_call.split('```json\\n')[1].split('\\n```')[0]\n",
    "order_items = json.loads(json_str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6706a22c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'item_name': 'Classic Club Sandwich', 'quantity': 2},\n",
       " {'item_name': 'Kheema Ghotala', 'quantity': 2}]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "order_items"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe950ac",
   "metadata": {},
   "source": [
    "## Trying from free api model GROQ or Langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9a7de0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from groq import Groq\n",
    "\n",
    "client = Groq(api_key=os.getenv('GROQ_API_KEY'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "071b2efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "completion = client.chat.completions.create(\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You're a restaurant order extractor. Match spoken order to menu items with price and return a just JSON list of item_name, price and price quantity. Nothing other than that\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"Menu items: {data}\\nCustomer said: {sample_input}\"\n",
    "        }\n",
    "    ],\n",
    "    temperature=1,\n",
    "    max_completion_tokens=1024,\n",
    "    # top_p=1,\n",
    "    # stream=True,\n",
    "    # stop=None,\n",
    ")\n",
    "\n",
    "# for chunk in completion:\n",
    "#     print(chunk.choices[0].delta.content or \"\", end=\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "61e47be8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'item_name': 'Classic Club Sandwich', 'price': 685, 'quantity': 2}, {'item_name': 'Kheema Ghotala', 'price': 785, 'quantity': 2}]\n"
     ]
    }
   ],
   "source": [
    "output_json = completion.choices[0].message.content\n",
    "order_items = json.loads(output_json)\n",
    "print(order_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2d691bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('C://Kiosks_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f6fb1d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "empty\n"
     ]
    }
   ],
   "source": [
    "path = 'models\\\\m'\n",
    "import os\n",
    "if not os.listdir(path):\n",
    "    print('empty') \n",
    "else:\n",
    "    print('d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12208e99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cefc45f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_model(self):\n",
    "        '''\n",
    "        \n",
    "        \n",
    "        '''\n",
    "        tokenizer = AutoTokenizer.from_pretrained(self.config['base_model_id'], token=token)\n",
    "        \n",
    "        model = AutoModelForCausalLM.from_pretrained(\n",
    "            self.config['base_model_id'],\n",
    "            device_map=\"auto\",            # Automatically uses GPU if available\n",
    "            torch_dtype=\"auto\",           # Adjusts precision\n",
    "            trust_remote_code=True,\n",
    "            token= token\n",
    "        )\n",
    "\n",
    "        # Optional: wrap in a pipeline\n",
    "        llm = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\n",
    "        \n",
    "        # Prompt (e.g., for restaurant order understanding)\n",
    "                \n",
    "        prompt =[{\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": \"You're a restaurant order extractor. Match spoken order to menu items with price and return a just JSON list of item_name, price and price quantity. Nothing other than that\"\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": f\"Menu items: {data}\\nCustomer said: {sample_input}\"\n",
    "                }]\n",
    "        prompt = json.dumps(prompt)\n",
    "                \n",
    "        response = llm(prompt, max_new_tokens=256, do_sample=False)[0][\"generated_text\"]\n",
    "        print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c80dfed7",
   "metadata": {},
   "source": [
    "# Loading and Testing Fine tunned model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74c9e415",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Kiosks_'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.chdir('C://Kiosks_')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e473f980",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "base_model_id = 'google/gemma-3-4b-it'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model_id)\n",
    "base_model = AutoModelForCausalLM.from_pretrained(base_model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba0b317",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
